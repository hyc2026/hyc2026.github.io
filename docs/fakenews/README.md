# 内容质量项目组

```pdf
/fakenews/summary.pdf
```

虚假信息的发布和传播会对社会造成很大的危害，如一些虚假的新闻会影响人们对重大事件的认知，一些伪科学内容会威胁人们的健康，造成财产损失等。

虚假信息鉴别成本高、难度大，不仅需要一定的领域知识和背景信息，同时对于新闻这类体裁，由于具有很高的时效性，其真实性也会随着时间的发展快速变化(佩洛西蹿台 2022.8.2 22:44)。此外，在进行虚假检测时，还要求模型具有语义推断的能力。

## 虚假信息检测的典型方法
### 风格检测
- 简单，搭建模型成本较低
- 召回率低

### 谣言检测
- 构建谣言库，可抽象为自然语言推断
- 手工录入谣言，无法发现新谣言

### 事实检测(存疑)
- 可发现新的不实信息
- 技术挑战大

### 用户评论/行为
- 特征容易挖掘
- 不实信息已经对用户造成了影响

### 传播模式挖掘
- 获取标注数据成本较低
- 检测准确率依赖于传播规模，不能及时发现谣言


## 目标
0展现阶段发现虚假信息

![LCT](zlct.jpg)

## 伪科学内容的识别

头条平台上有很多人可以自由上传文章视频，有很多人借此宣传伪科学内容来吸粉。我们希望通过一个文本分类任务鉴别出伪科学内容进行打压。

数据：平台中被人为审核过后被打压为虚假的作为正例，人为审核后不打压的作为负例。存在正负例不均衡问题（训练时将正例翻倍），训练数据不足（使用伪标签，用第一轮模型预测没有人审核的数据，把置信度高的打上标签作为训练数据）

写伪科学的人会根据打压情况不断调整自己的写作风格，因此需要不断获取新的数据更新模型

模型识别出的例子还会进行人为审核，因此该任务更注重召回率

### 数据来源

- 头条：图文、微头条、问答
- 抖音：小视频标题以及通过ocr和asr获取的文字信息
- 西瓜：中视频标题以及通过ocr和asr获取的文字信息

### 存在问题及解决方案

训练数据距今时间较长，很多作者会针对之前的模型进行对抗，使得模型检测不出。需要收集新的数据进行训练。未来希望能形成自动化数据收集及定期训练和改进模型。

### 模型结构

使用6层Albert预训练模型作为baseline，输出的[CLS] token经过sigmoid函数作为虚假的概率。

![fakescience](fakescience.png)

### 工作流程

#### 更新现有模型

1. 数据抓取和清洗：使用SQL在数据库中抓取数据，筛选出人工审核后进行打压的数据作为正例，不打压的数据作为负例。
2. 数据增强：由于正例过少，采用正利double，负例亚采样的方式，保证正负例比例在1:5左右。
3. 构造数据集：按时间由远及近分别构造训练集、验证集和测试集，比例大约为10:1:1。
4. 模型训练及验证：训练模型，使用验证集选取checkpoint并在测试集上进行测试。
5. 人工检验模型效果：将模型命中的数据进行人工标注，验证模型的打压率。

#### 实现模型自动更新

将上述更新模型流程自动化，自动抓取数据，进行数据增强，训练模型，在相同的测试集下测试新旧模型的效果，效果有提升则自动更新线上模型。

## 虚假新闻检测

###  物理架构

![lct](lct.jpg)

如上图所示，`虚假新闻检测`服务主要依赖`抽取模型Extract`，一个由Redis、ES和Mysql组成的信源库以及一个检索服务。其中抽取模型从用户的发文中抽取出关键句子；检索服务以抽取的关键句子为query在信源库中进行检索，粗筛出一批信源，并由推断模型进行判断，输出关键句子是否有信源支持以及是否与已有信源矛盾。无信源的内容会由专业审核人员进行审核，并反馈审核结果和优化模型。

虚假新闻检测主要采用了白名单的策略，对于没有检索到信源的发文认为存在虚假的可能。

### 抽取模型

抽取模型在用于在一段文本中抽取出值得进行虚假检测的关键span，同时完成事件完整性和检测价值判断。

> #深圳职业故事#非深圳户籍就业人员随迁子女中考管理办法发布。总结起来，在深圳有缴纳社保，有稳定工作，有居住证，有稳定住的地方，有稳定收入，不是深户，子女也可以参加中考，有机会在公办高中就读了，有机会接受更好的优质教育了，更有机会成才了。不像以前，一中考，就考虑回老家读高中了。具体要求，大家可以...

- `重要事件`：非深圳户籍就业人员随迁子女中考管理办法发布
- `冗余`：非深圳户籍就业人员随迁子女中考管理办法发布。总结起来，在深圳有缴纳社保，有稳定工作，有居住证，有稳定住的地方，有稳定收入，不是深户，子女也可以参加中考
- `事件不完整`：机会在公办高中就读了

### 推断模型

用于判断两个句子之间的关系，返回5分类结果：“蕴含”，“部分蕴含”，“反对”，“弱相关”和“不相关”。

### 信源库

- `抓取服务`：选取一部分国内外权威网站（新华社、BBC等），针对每个网站制定抓取策略，定期对其新发文进行抓取，并将抓取结果保存在消息队列中。
- `消费订阅信源`：对消息队列中的抓取结果进行消费，对于国外网站内容，首先会调用翻译服务进行语言自动检测及翻译。对抓取到的内容调用抽取模型进行抽取，并将抽取结果保存在权威信源库中作为权威信源。

### 临时信源库

- 热榜内容自动入库：热榜内容很多是突发的高热度事件，其内容是经过审核的但是没有录入权威信源库。将热榜内容自动录入临时信源库，设定信源时效并采用精确匹配的方式与抽取关键句子进行比对。
- 多次进审不打压内容：一些发文审核人员认为不需要打压，但是模型没有检索到信源。针对这些内容进行聚类处理，并将其录入临时信源库，采用NLI匹配的方式与抽取关键句子进行比对

### 检索服务

- 检索信源库：使用抽取到的关键句子作为query在es信源库、es临时信源库和redis临时信源库中进行检索。
- 综合搜索：使用抽取到的关键句子作为query在头条综合搜索检索信源。
- 匹配和推断：检索结果还将经过推断模型判断，判断为相关的内容将作为信源返回，否则认为没有信源。
